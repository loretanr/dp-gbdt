<?xml version="1.0" ?>
<cherrytree>
	<node custom_icon_id="0" foreground="" is_bold="True" name="Meeting notes" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1619168425.57" ts_lastsave="1621427507.62" unique_id="1">
		<rich_text>Thu 3pm
Link:  </rich_text>
		<rich_text foreground="#3d3c40"> </rich_text>
		<rich_text link="webs https://ethz.zoom.us/j/4333973638">https://ethz.zoom.us/j/4333973638</rich_text>
		<node custom_icon_id="0" foreground="" is_bold="False" name="04_22_first" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1619168455.86" ts_lastsave="1619595361.65" unique_id="2">
			<rich_text scale="h2">Discussion points</rich_text>
			<rich_text>

More details on the tasks in the thesis description:

• Task 0
   ◇ ~2 weeks
   ◇ Also hello world enclave in SGX dev environment, with i/o and r/w from disk

• Task 3
   ◇ depends on the results from 1 and 2

• Task 4
   ◇ Running the algorithm multiple times on the same input, can weaken the randomness/privacy guarantees of the privacy-preserving part. we need to avoid that. Kari and Esfandiari have ideas.

• Task 5
   ◇ we'll see how much time we have for this

• Task ...
   ◇ Where “real research” resp new things would happen
   ◇ This could very well be the hardest task if we get here

• Task n
   ◇ 1 month for writing


</rich_text>
			<rich_text scale="h2">Organization</rich_text>
			<rich_text>

• Weekly thursday meetings 3PM
   ◇ maybe daily updates to mattermost?


</rich_text>
			<rich_text scale="h2">Next steps</rich_text>
			<rich_text>

• Read about the ML algorithm
• Fully read the papers
• Hello world enclave as described above.
• prepare eth paperwork for thesis start
</rich_text>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="04_29" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1619595361.65" ts_lastsave="1620053169.37" unique_id="3">
			<rich_text scale="h2">What I did the past week</rich_text>
			<rich_text>

• Reading “Intel SGX explained” paper (120 pages, from MIT)
   ◇ gone through background on computer architecture (CPU and memory)

• Read Theos thesis (except synthetic data generation)
   ◇ understand the idea of  Decision Trees and Gradient Boosting, Differential privacy
      ▪ how exactly the formulas are derived, not clear

• Working/backup private github repo
   ◇ because no permission for ethz gitlab
   ◇ add and share link with you in mettermost?
      ▪ would need github names
   ◇ Time log excel
   ◇ </rich_text>
			<rich_text foreground="#ffffc0c0cbcb">write in mattermost whenever I finished a task</rich_text>
			<rich_text>
      ▪ then you can add something if you want

• Read side channel papers
   ◇ finished 2/6 (oldest ones)

• can run enclaves in my OS
   ◇ not yet created my own enclave
   ◇ but checked out and ran the SampleEnclave that installation comes with

----------------------------- still TODO ----------------------------------

• read the GBDT paper
• run theos algorithm to understand it better
   ◇ compare code and thesis
   ◇ understand what's new compared to the GBDT paper
• need to read the rest of the side-channel papers
• play around with the hello world enclave

-------------------------------------------------------------------------------

</rich_text>
			<rich_text scale="h2">Questions</rich_text>
			<rich_text>   </rich_text>
			<rich_text background="#ffffffff0000" foreground="#1a1a1a1a1a1a">TODO</rich_text>
			<rich_text>

• Looking at the the python code.... when generating a cpp algorithm
   ◇ math, ML and other libraries?
      ▪ just use whatever cpp libraries I can find?
      ▪ or what's the strategy here
      ▪ other recommandations from you guys, maybe you've already done it?

==========================================

</rich_text>
			<rich_text scale="h2">Discussion Points</rich_text>
			<rich_text>

• Order for reading papers:
   ◇ </rich_text>
			<rich_text link="webs https://docs.google.com/document/d/1ht7h--tp0ivNH9Z8S1tpoRoyzN_Q7DVU3sHaoRdDktw/edit?ts=608aacbd#">https://docs.google.com/document/d/1ht7h--tp0ivNH9Z8S1tpoRoyzN_Q7DVU3sHaoRdDktw/edit?ts=608aacbd#</rich_text>
			<rich_text>
   ◇ skip rollback paper for now

• Take notes when reading!

• ML: do Tutorials

• Theo could explain his code

• Can officially start mid May

</rich_text>
			<rich_text scale="h3">Next steps</rich_text>
			<rich_text>

• Read read read and make notes
• submit thesis proposal</rich_text>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="05_06" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1620053169.39" ts_lastsave="1620308160.81" unique_id="4">
			<rich_text scale="h2">Questions</rich_text>
			<rich_text>

</rich_text>
			<rich_text foreground="#9090eeee9090">DP-GBDT proposes 2 level structure Ensemble of Ensembles.</rich_text>
			<rich_text>
   ◇ The first step splits the input data trees are created using parallel composition
   ◇ 2nd step would create multiple such ensembles and do sequential composition
      ▪ this is left away in Theos thesis, right? Was there a reason (besides time maybe)
      ▪ if an enclave would do multiple such 2nd steps that would be similar to the adversary doing rollback attack
</rich_text>
			<rich_text foreground="#ffffa5a50000">• It was sufficient to do the inner level
• and by doing the outer you would gain accurracy and lose privacy</rich_text>
			<rich_text>

</rich_text>
			<rich_text foreground="#9090eeee9090">How can the insurance now learn from the model?</rich_text>
			<rich_text>
</rich_text>
			<rich_text foreground="#ffffa5a50000">• The trees are not useless, need to check evaluation/appendix of thesis
• especially the inner nodes have a good probability to be the most important ones on top etc.</rich_text>
			<rich_text>

Let's say we need 500 companies' data for a meaningful model. Until we collected that many, the questionnaires are not useful. So we would need to store them somewhere. (encrypted etc probably).
   ◇ And when we have 500 we feed it to the enclave
   ◇ </rich_text>
			<rich_text foreground="#9090eeee9090">What if we feed 400 distinct, and then 100x the same company, or maybe some other clever pattern?</rich_text>
			<rich_text>
</rich_text>
			<rich_text foreground="#ffffa5a50000">• we need to define those things, and specify such rules in the enclave code (attestation)
• Or there may be some approaches where the data deletes itself after 1 run or something
• we kind of need to find out this kind of things</rich_text>
			<rich_text>

-------------------------------------------------------------
</rich_text>
			<rich_text scale="h3">3 options for coding</rich_text>
			<rich_text>

• \exists way to run python code in enclave -&gt; bad, much code, how to secure
• use C DPDT implementation, start from there
   ◇ </rich_text>
			<rich_text link="webs https://github.com/yarny/gbdt">https://github.com/yarny/gbdt</rich_text>
			<rich_text>
   ◇ however this code is (highly) optimized
• </rich_text>
			<rich_text foreground="#ffffc0c0cbcb">do it from scratch</rich_text>
			<rich_text>
   ◇ can use libraries as much as we want for non-secret dependant parts
   ◇ but do the secret dependant parts on my own
      ▪ then we know them exactly

------------- next steps -------------------
• finish reading
• Tell Kari to setup a meeting with Theo as soon as I'm ready
• get to know Theos code

</rich_text>
		</node>
	</node>
	<node custom_icon_id="0" foreground="#ff0000" is_bold="True" name="Implementation notes" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1621427507.64" ts_lastsave="1621427568.33" unique_id="5">
		<rich_text>TODO
• run
• run with info flag



Big picture

• translate to CPP, using libraries where possible


Questions
• How are we gonna identify secret dependant stuff (-&gt; replace  library code with my own there)</rich_text>
	</node>
</cherrytree>
