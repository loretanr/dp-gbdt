<?xml version="1.0" ?>
<cherrytree>
	<node custom_icon_id="0" foreground="" is_bold="True" name="Meeting notes" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1619168425.57" ts_lastsave="1623939126.81" unique_id="1">
		<rich_text>Thu 3pm
Link:  </rich_text>
		<rich_text foreground="#3d3c40"> </rich_text>
		<rich_text link="webs https://ethz.zoom.us/j/4333973638">https://ethz.zoom.us/j/4333973638</rich_text>
		<rich_text>



</rich_text>
		<node custom_icon_id="0" foreground="" is_bold="False" name="04_22_first" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1619168455.86" ts_lastsave="1619595361.65" unique_id="2">
			<rich_text scale="h2">Discussion points</rich_text>
			<rich_text>

More details on the tasks in the thesis description:

• Task 0
   ◇ ~2 weeks
   ◇ Also hello world enclave in SGX dev environment, with i/o and r/w from disk

• Task 3
   ◇ depends on the results from 1 and 2

• Task 4
   ◇ Running the algorithm multiple times on the same input, can weaken the randomness/privacy guarantees of the privacy-preserving part. we need to avoid that. Kari and Esfandiari have ideas.

• Task 5
   ◇ we'll see how much time we have for this

• Task ...
   ◇ Where “real research” resp new things would happen
   ◇ This could very well be the hardest task if we get here

• Task n
   ◇ 1 month for writing


</rich_text>
			<rich_text scale="h2">Organization</rich_text>
			<rich_text>

• Weekly thursday meetings 3PM
   ◇ maybe daily updates to mattermost?


</rich_text>
			<rich_text scale="h2">Next steps</rich_text>
			<rich_text>

• Read about the ML algorithm
• Fully read the papers
• Hello world enclave as described above.
• prepare eth paperwork for thesis start
</rich_text>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="04_29" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1619595361.65" ts_lastsave="1620053169.37" unique_id="3">
			<rich_text scale="h2">What I did the past week</rich_text>
			<rich_text>

• Reading “Intel SGX explained” paper (120 pages, from MIT)
   ◇ gone through background on computer architecture (CPU and memory)

• Read Theos thesis (except synthetic data generation)
   ◇ understand the idea of  Decision Trees and Gradient Boosting, Differential privacy
      ▪ how exactly the formulas are derived, not clear

• Working/backup private github repo
   ◇ because no permission for ethz gitlab
   ◇ add and share link with you in mettermost?
      ▪ would need github names
   ◇ Time log excel
   ◇ </rich_text>
			<rich_text foreground="#ffffc0c0cbcb">write in mattermost whenever I finished a task</rich_text>
			<rich_text>
      ▪ then you can add something if you want

• Read side channel papers
   ◇ finished 2/6 (oldest ones)

• can run enclaves in my OS
   ◇ not yet created my own enclave
   ◇ but checked out and ran the SampleEnclave that installation comes with

----------------------------- still TODO ----------------------------------

• read the GBDT paper
• run theos algorithm to understand it better
   ◇ compare code and thesis
   ◇ understand what's new compared to the GBDT paper
• need to read the rest of the side-channel papers
• play around with the hello world enclave

-------------------------------------------------------------------------------

</rich_text>
			<rich_text scale="h2">Questions</rich_text>
			<rich_text>   </rich_text>
			<rich_text background="#ffffffff0000" foreground="#1a1a1a1a1a1a">TODO</rich_text>
			<rich_text>

• Looking at the the python code.... when generating a cpp algorithm
   ◇ math, ML and other libraries?
      ▪ just use whatever cpp libraries I can find?
      ▪ or what's the strategy here
      ▪ other recommandations from you guys, maybe you've already done it?

==========================================

</rich_text>
			<rich_text scale="h2">Discussion Points</rich_text>
			<rich_text>

• Order for reading papers:
   ◇ </rich_text>
			<rich_text link="webs https://docs.google.com/document/d/1ht7h--tp0ivNH9Z8S1tpoRoyzN_Q7DVU3sHaoRdDktw/edit?ts=608aacbd#">https://docs.google.com/document/d/1ht7h--tp0ivNH9Z8S1tpoRoyzN_Q7DVU3sHaoRdDktw/edit?ts=608aacbd#</rich_text>
			<rich_text>
   ◇ skip rollback paper for now

• Take notes when reading!

• ML: do Tutorials

• Theo could explain his code

• Can officially start mid May

</rich_text>
			<rich_text scale="h3">Next steps</rich_text>
			<rich_text>

• Read read read and make notes
• submit thesis proposal</rich_text>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="05_06" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1620053169.39" ts_lastsave="1620308160.81" unique_id="4">
			<rich_text scale="h2">Questions</rich_text>
			<rich_text>

</rich_text>
			<rich_text foreground="#9090eeee9090">DP-GBDT proposes 2 level structure Ensemble of Ensembles.</rich_text>
			<rich_text>
   ◇ The first step splits the input data trees are created using parallel composition
   ◇ 2nd step would create multiple such ensembles and do sequential composition
      ▪ this is left away in Theos thesis, right? Was there a reason (besides time maybe)
      ▪ if an enclave would do multiple such 2nd steps that would be similar to the adversary doing rollback attack
</rich_text>
			<rich_text foreground="#ffffa5a50000">• It was sufficient to do the inner level
• and by doing the outer you would gain accurracy and lose privacy</rich_text>
			<rich_text>

</rich_text>
			<rich_text foreground="#9090eeee9090">How can the insurance now learn from the model?</rich_text>
			<rich_text>
</rich_text>
			<rich_text foreground="#ffffa5a50000">• The trees are not useless, need to check evaluation/appendix of thesis
• especially the inner nodes have a good probability to be the most important ones on top etc.</rich_text>
			<rich_text>

Let's say we need 500 companies' data for a meaningful model. Until we collected that many, the questionnaires are not useful. So we would need to store them somewhere. (encrypted etc probably).
   ◇ And when we have 500 we feed it to the enclave
   ◇ </rich_text>
			<rich_text foreground="#9090eeee9090">What if we feed 400 distinct, and then 100x the same company, or maybe some other clever pattern?</rich_text>
			<rich_text>
</rich_text>
			<rich_text foreground="#ffffa5a50000">• we need to define those things, and specify such rules in the enclave code (attestation)
• Or there may be some approaches where the data deletes itself after 1 run or something
• we kind of need to find out this kind of things</rich_text>
			<rich_text>

-------------------------------------------------------------
</rich_text>
			<rich_text scale="h3">3 options for coding</rich_text>
			<rich_text>

• \exists way to run python code in enclave -&gt; bad, much code, how to secure
• use C DPDT implementation, start from there
   ◇ </rich_text>
			<rich_text link="webs https://github.com/yarny/gbdt">https://github.com/yarny/gbdt</rich_text>
			<rich_text>
   ◇ however this code is (highly) optimized
• </rich_text>
			<rich_text foreground="#ffffc0c0cbcb">do it from scratch</rich_text>
			<rich_text>
   ◇ can use libraries as much as we want for non-secret dependant parts
   ◇ but do the secret dependant parts on my own
      ▪ then we know them exactly

------------- next steps -------------------
• finish reading
• Tell Kari to setup a meeting with Theo as soon as I'm ready
• get to know Theos code

</rich_text>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="05_20" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1621517715.69" ts_lastsave="1621517939.67" unique_id="6">
			<rich_text>• we'll try and find secret dependant accesses by hand first!
   ◇ because tools can be messy!
   ◇ esfanidar sent a paper for such a tool </rich_text>
			<rich_text link="webs https://hal.inria.fr/hal-01658653/document">https://hal.inria.fr/hal-01658653/document</rich_text>
			<rich_text>

• TODO create a shared google docs with the 2 algorithms from the DPGDBDT paper
   ◇ (</rich_text>
			<rich_text link="webs https://ojs.aaai.org//index.php/AAAI/article/view/5422">https://ojs.aaai.org//index.php/AAAI/article/view/5422</rich_text>
			<rich_text>)
   ◇ need to be able to annotate each part with our ideas whether it is potentially risky
   ◇ and need space to insert solutions like “use list, loop through all nodes etc”</rich_text>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="05_28" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1622210274.9" ts_lastsave="1622213346.65" unique_id="10">
			<rich_text>
• High level analysis of the algorithm side channel was ok.
    But at some point we need a more detailed overview of the problem and how my implementation solves it.

• Had difficulties to explain the The [0,1] probabilities addition thingy. 
        The thing that Theo does to implement the exponential mechanism.
        is named something like CTF (probability distribution) with increasing balkens something.
        
        
        
</rich_text>
			<rich_text scale="h2">Q &amp; A</rich_text>
			<rich_text>

</rich_text>
			<rich_text foreground="#9090eeee9090">do you see any difference in this approach vs creating all 50 sets at once</rich_text>
			<rich_text>
    “unused samples are not put back”
    </rich_text>
			<rich_text foreground="#ffffa5a50000">Esfandiar sees privacy dangers in this approach</rich_text>
			<rich_text>
        </rich_text>
			<rich_text foreground="#ffffa5a50000">if there's a tree whose ability to improve the model (discard tree or not) depends on 1 point</rich_text>
			<rich_text>
            then someone might learn something somehow. Esfandiar thinks so.
            maybe an adversary could recognize whether a sample “put back” resp. used again

</rich_text>
			<rich_text foreground="#9090eeee9090">is it normal for GBDT that you end up using less tree than specified?</rich_text>
			<rich_text>
   •  when tested, out of 50 possible trees it ended up being ~25
   •  so half of the training data was not &quot;used&quot; 
   •  but we still paid privacy budget for it
</rich_text>
			<rich_text foreground="#ffffa5a50000">   • It's not normal, normal GBDT improve with every tree.
      ◇  but it makes sense because of DP! Randomization can create useless trees</rich_text>
			<rich_text>

</rich_text>
			<rich_text foreground="#9090eeee9090">Do you think that leaks information if we don't keep trees that are not used for prediction later?
    </rich_text>
			<rich_text foreground="#ffffa5a50000">YES, must keep all trees! (Esfandiar)</rich_text>
			<rich_text>
    
</rich_text>
			<rich_text foreground="#9090eeee9090">start with bfs / dfs / 2-nodes ?   Need all 3 in final implementation?</rich_text>
			<rich_text>
   •  2-nodes was best
   </rich_text>
			<rich_text foreground="#ffffa5a50000">• would be nice to have all options</rich_text>
			<rich_text>

</rich_text>
			<rich_text foreground="#9090eeee9090">which dataset am I working with? synthetic I guess?</rich_text>
			<rich_text>
       </rich_text>
			<rich_text foreground="#ffffa5a50000">• would be nice to have all abalones and datasets!</rich_text>
			<rich_text>
       
    
</rich_text>
			<rich_text scale="h2">TODO</rich_text>
			<rich_text> next steps:
   ◇ we need to check with higher privacy budget. Then less trees should get discarded.

   ◇ </rich_text>
			<rich_text weight="heavy">Remove the “put back ” strategy in python code and see whether it works as good as Theo’s code does.</rich_text>
			<rich_text>
</rich_text>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="06_03" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1622727420.89" ts_lastsave="1623056086.55" unique_id="13">
			<rich_text> discussing and Q&amp;A also here
 
    </rich_text>
			<rich_text link="webs https://docs.google.com/document/d/1GaqAwNijzrrf_228VdCj4WU4N1dySOratf2DJ6VN3XI/edit#">https://docs.google.com/document/d/1GaqAwNijzrrf_228VdCj4WU4N1dySOratf2DJ6VN3XI/edit#</rich_text>
			<rich_text>
    
    
    
Q &amp; A

   •  The scaling to [-1,1] in Theos code is necessary for the proof.
      ◇ If those values would be larger we would need more noise
      ◇  the 3 in delta G sensitivity calculation (in code) is because of the scaling!


TODO
   ◇ create clean graphs
   ◇ especially one that uses alltrees and no rejection for pb 0.5 to 4
   ◇ debugger how many instances where (abalone + maybe some larger dataset?)
   ◇ put __pycache__'s in gitignore if not already.
   ◇ done </rich_text>
			<rich_text link="webs https://docs.google.com/document/d/1CEYstt6WXV2DO6hBD7ENk2zDl_5xUWXYuJB7Cd5PjUw/edit">https://docs.google.com/document/d/1CEYstt6WXV2DO6hBD7ENk2zDl_5xUWXYuJB7Cd5PjUw/edit</rich_text>
			<rich_text>

TODO 
    check out Theos meeting slides.</rich_text>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="06_10" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1623331472.64" ts_lastsave="1623332681.42" unique_id="14">
			<rich_text foreground="#9090eeee9090">How does the mighty “proof” of Moritz look?</rich_text>
			<rich_text>
•  got the DPGBDT proof from esfandiar 
   ◇ I don't understand anything
    
</rich_text>
			<rich_text foreground="#9090eeee9090">do you have an idea of how I could create a better overview of algorithm and implementation to reason about side channel stuff?</rich_text>
			<rich_text>
   •  need some form of more detailed pseudocode (with more details)

</rich_text>
			<rich_text foreground="#9090eeee9090">Only y is scaled right? because we only will add noise to predictions. Right?
Or do we need to scale X before training? Or does it not make a difference?</rich_text>
			<rich_text>
    </rich_text>
			<rich_text foreground="#ffffa5a50000">Esfandiar says only the labels (y)</rich_text>
			<rich_text>
    o/w read the base paper...
    
    
</rich_text>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="06_17" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1623939008.65" ts_lastsave="1623939129.56" unique_id="15">
			<rich_text>• need to indicate after each pseudocode, what exactly it could leak in its current form (even algorithm parameters)

• special consideration to all branches like the ones on top of find_best_split

• special consideration required for stuff like “continue;”</rich_text>
		</node>
	</node>
	<node custom_icon_id="0" foreground="#ff0000" is_bold="True" name="Implementation notes" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1621427507.64" ts_lastsave="1624106103.59" unique_id="5">
		<rich_text foreground="#a0a02020f0f0" scale="h2">&quot;example.py&quot;</rich_text>
		<rich_text>
(</rich_text>
		<rich_text weight="heavy">abalone clams</rich_text>
		<rich_text>, 0.1 budget)
   ☑ run
   ☑ run with info/debug
   ☑ performs DFS,BFS,3-nodes
      ◇ RMSE from 4.x - 2.7 and the alternate who's best
         </rich_text>
		<rich_text foreground="#9090eeee9090">▪ How good is a RMSE of 3?</rich_text>
		<rich_text>

</rich_text>
		<rich_text foreground="#a0a02020f0f0" scale="h2">&quot;example_classification.py&quot;</rich_text>
		<rich_text>
</rich_text>
		<rich_text weight="heavy">classify samples from 3 random normal distributions that were scrambled</rich_text>
		<rich_text>

</rich_text>
		<rich_text foreground="#a0a02020f0f0" scale="h2">&quot;evaluation/attack.py&quot;</rich_text>
		<rich_text>
</rich_text>
		<rich_text weight="heavy">membership</rich_text>
		<rich_text> </rich_text>
		<rich_text weight="heavy">inference</rich_text>
		<rich_text>
   ◇ not working as is

</rich_text>
		<rich_text foreground="#a0a02020f0f0">&quot;</rich_text>
		<rich_text foreground="#a0a02020f0f0" scale="h2">results/</rich_text>
		<rich_text foreground="#a0a02020f0f0">&quot;</rich_text>
		<rich_text>
   •  n1 python plot.py's ready

    </rich_text>
		<rich_text weight="heavy">cross_val.py</rich_text>
		<rich_text>
      •   takes long
      •   --------- Processing Model DPREF, outputs only a bunch of LightGBM unknown param warnings
      • And the values I get are also much worse than the ones on github
      • so DPRef not working, skipping for now!
      • </rich_text>
		<rich_text foreground="#9090eeee9090">what is DP_Ref</rich_text>
		<rich_text>, it seems DP, but what and why is it in code. Can't find in thesis

&quot;</rich_text>
		<rich_text foreground="#a0a02020f0f0" scale="h2">baseline</rich_text>
		<rich_text scale="h2">/</rich_text>
		<rich_text>&quot;
    code for evalutating baseliine models on the reference dataset
   •  seems ot be the non-DP code
   • Uses LightGBM, which is a paper proposing an improvement over standard GBDT 
   • grid search cross validation
   • takes really long to run

</rich_text>
		<rich_text scale="h2">“</rich_text>
		<rich_text foreground="#a0a02020f0f0" scale="h2">model.py</rich_text>
		<rich_text scale="h2">”</rich_text>
		<rich_text>
• </rich_text>
		<rich_text foreground="#93a1a1" weight="heavy">class</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy"> </rich_text>
		<rich_text foreground="#cb4b16" weight="heavy">GradientBoostingEnsemble</rich_text>
		<rich_text>
• </rich_text>
		<rich_text foreground="#93a1a1" weight="heavy">class</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy"> </rich_text>
		<rich_text foreground="#cb4b16" weight="heavy">DecisionNode</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy">:</rich_text>
		<rich_text>
• </rich_text>
		<rich_text foreground="#93a1a1" weight="heavy">class</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy"> </rich_text>
		<rich_text foreground="#cb4b16" weight="heavy">TreeExporter</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy">:</rich_text>
		<rich_text>
• </rich_text>
		<rich_text foreground="#93a1a1" weight="heavy">class</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy"> </rich_text>
		<rich_text foreground="#cb4b16" weight="heavy">DifferentiallyPrivateTree</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy">(</rich_text>
		<rich_text foreground="#6c71c4" weight="heavy">BaseEstimator</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy">):</rich_text>
		<rich_text>

</rich_text>
		<rich_text scale="h2">“</rich_text>
		<rich_text foreground="#a0a02020f0f0" scale="h2">evaluation/estimator.py</rich_text>
		<rich_text scale="h2">&quot;</rich_text>
		<rich_text>
• </rich_text>
		<rich_text foreground="#93a1a1" weight="heavy">class</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy"> </rich_text>
		<rich_text foreground="#cb4b16" weight="heavy">DPGBDT</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy">(</rich_text>
		<rich_text foreground="#6c71c4" weight="heavy">BaseEstimator</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy">):</rich_text>
		<rich_text>
   ◇ </rich_text>
		<rich_text foreground="#93a1a1" weight="heavy">def</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy"> </rich_text>
		<rich_text foreground="#268bd2" weight="heavy">fit</rich_text>
		<rich_text>
   ◇ </rich_text>
		<rich_text foreground="#93a1a1" weight="heavy">def</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy"> </rich_text>
		<rich_text foreground="#268bd2" weight="heavy">predict</rich_text>
		<rich_text>
   ◇ </rich_text>
		<rich_text foreground="#93a1a1" weight="heavy">def</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy"> </rich_text>
		<rich_text foreground="#268bd2" weight="heavy">predict_proba</rich_text>
		<rich_text>
   ◇ </rich_text>
		<rich_text foreground="#93a1a1" weight="heavy">def</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy"> </rich_text>
		<rich_text foreground="#268bd2" weight="heavy">decision_path</rich_text>
		<rich_text>
• </rich_text>
		<rich_text foreground="#93a1a1" weight="heavy">class</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy"> </rich_text>
		<rich_text foreground="#cb4b16" weight="heavy">DPRef</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy">(</rich_text>
		<rich_text foreground="#6c71c4" weight="heavy">BaseEstimator</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy">):</rich_text>
		<rich_text>
   ◇ similar
uses resp. wraps around the model.py stuff. </rich_text>
		<rich_text foreground="#ffffa5a50000">It's to use sklearn.cross_val on a DPGBDT object.</rich_text>
		<rich_text>

--------------------------------------------------------

☐ test print decision tree functionality
   ◇ </rich_text>
		<rich_text foreground="#93a1a1" weight="heavy">class</rich_text>
		<rich_text foreground="#bbbbbb" weight="heavy"> </rich_text>
		<rich_text foreground="#cb4b16" weight="heavy">TreeExporter</rich_text>
		<rich_text> in model.py
   ◇ no usage in project
   ◇ creates attributes such that sklearn.tree.plot_tree could plot it

============================

Big picture

• translate to CPP, using libraries where possible


Questions
• </rich_text>
		<rich_text foreground="#9090eeee9090">How are we gonna identify secret dependant stuff (-&gt; replace  library code with my own there)</rich_text>
		<rich_text>
• so far the code seems to make sense, is well commentated
• maybe give me theos information and I'll question him as rquired.


--------------------------------------
go through the 2 pseudocode algorithms in 
make shared google docs with comments at each step whether its secret dependant.


gonna be interesting how fast the CPP is, since Python used automatic sklearn multithreading (4 threads on my laptop)</rich_text>
		<node custom_icon_id="0" foreground="" is_bold="False" name="creating a single tree" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1621853459.74" ts_lastsave="1622032046.54" unique_id="7">
			<rich_text scale="h1">creating a single tree</rich_text>
			<rich_text>

ressources to check before start:

• implementation ideas from theo
• implementation ideas from github_gbdt
• Implementation ideas from the internet
   ◇ n1 Makefile </rich_text>
			<rich_text link="webs https://github.com/qiyiping/gbdt/blob/master/src/cpp/Makefile">https://github.com/qiyiping/gbdt/blob/master/src/cpp/Makefile</rich_text>
			<rich_text>
   ◇ smaller, better overview decision tree repo, but Chinese comments
      ▪ </rich_text>
			<rich_text link="webs https://github.com/zhaoxingfeng/XGBoost-cpp/blob/master/src/decision_tree.cpp">https://github.com/zhaoxingfeng/XGBoost-cpp/blob/master/src/decision_tree.cpp</rich_text>
			<rich_text>
      ▪ </rich_text>
			<rich_text link="webs https://github.com/HrBlack/GBDT/blob/master/decision_tree.cpp">https://github.com/HrBlack/GBDT/blob/master/decision_tree.cpp</rich_text>
			<rich_text>
   ◇ 
• stuff from the paper



==============================
What I need:
   •  train() / fit()
      ◇ loop to grow_tree() each tree in the ensemble
   • grow_tree()
      ◇ XGBoost uses a queue
      ◇ HrBlack/GBDT uses 2 lists that he pushes into
      ◇ XGBoost-cpp uses class Tree with attributes like split_val, left_child etc.
      ◇ Theo builds it recursively with MakeTreeBFS/DFS -&gt; create nodes and point to the children etc.
         ▪ the logic is all there, no ML library used.</rich_text>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="questions" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1622108984.01" ts_lastsave="1622213562.55" unique_id="8">
			<rich_text foreground="#9090eeee9090">start with bfs / dfs / 2-nodes ?   Need all 3 in final implementation?</rich_text>
			<rich_text>
   •  2-nodes was best
   </rich_text>
			<rich_text foreground="#ffffa5a50000">• yeah want all</rich_text>
			<rich_text>

</rich_text>
			<rich_text foreground="#9090eeee9090">which dataset am I working with? synthetic I guess?</rich_text>
			<rich_text>
    </rich_text>
			<rich_text foreground="#ffffa5a50000">all, but synthetic will later be the focus</rich_text>
			<rich_text>

</rich_text>
			<rich_text foreground="#9090eeee9090">multi classification necessary?</rich_text>
			<rich_text>
   </rich_text>
			<rich_text foreground="#ffffa5a50000"> if some dataset requires it, yes, because we want all the abalones etc</rich_text>
			<rich_text>

-------------------------------------
</rich_text>
			<rich_text foreground="#9090eeee9090">which options to implement</rich_text>
			<rich_text>
• </rich_text>
			<rich_text foreground="#ffffa5a50000">we want almost all of them (Esfandiar)</rich_text>
			<rich_text>
• bfs / dfs / 2-nodes (best, mostly)
   ◇ Default I'll do 
      ▪ 2-nodes, (with Leaf clipping and gradient filtering)
      ▪ balance partition = yes  (aka same number of trees per ensemble)
• Looking at it it all makes sense, or is not much overhead for me anyway
• questionable
   ◇ use_decay (&quot;</rich_text>
			<rich_text foreground="#2aa198">internal node privacy budget has a decaying factor</rich_text>
			<rich_text>&quot;)
      ▪ by default off, in results/  it's also never used.
      ▪ so this probably means it was not useful resp “can worsen accuracy” according to GLC section of base paper
      ▪ but implementation overhead is tiny.

• “according to thesis” GDF (filtering) can be selectively enabled.
   ◇ </rich_text>
			<rich_text foreground="#ffffa5a50000">the instances with a very large gradient are often outliers in the training data set since they cannot be well learned by GBDTs. Thus, it is reasonable to learn a tree by filtering those</rich_text>
			<rich_text>
outliers.
   ◇ simple option model.py line ~295
   ◇ can later test whether it makes any difference
      ▪ leave away for now.


-------------------------------------------------
</rich_text>
			<rich_text foreground="#9090eeee9090">do you see any difference in this approach vs creating all 50 sets at once</rich_text>
			<rich_text>
    “unused samples are not put back”
    </rich_text>
			<rich_text foreground="#ffffa5a50000">Esfandiar sees privacy dangers in this approach</rich_text>
			<rich_text>
        </rich_text>
			<rich_text foreground="#ffffa5a50000">if there's a tree whose ability to improve the model (discard tree or not) depends on 1 point</rich_text>
			<rich_text>
            then someone might learn something somehow. Esfandiar thinks so.
            maybe an adversary could recognize whether a sample “put back” resp. used again

</rich_text>
			<rich_text foreground="#9090eeee9090">is it normal for GBDT that you end up using less tree than specified?</rich_text>
			<rich_text>
   •  when tested, out of 50 possible trees it ended up being ~25
   •  so half of the training data was not &quot;used&quot; 
   •  but we still paid privacy budget for it
</rich_text>
			<rich_text foreground="#ffffa5a50000">   • It's not normal, but it makes sense because of DP! Randomization can create useless trees</rich_text>
			<rich_text>

</rich_text>
			<rich_text foreground="#9090eeee9090">Do you think that leaks information if we don't keep trees that are not used for prediction later?
    </rich_text>
			<rich_text foreground="#ffffa5a50000">YES, must keep all trees! (Esfandiar)</rich_text>
			<rich_text foreground="#9090eeee9090">

</rich_text>
			<rich_text foreground="#ffffffffffff">==============================</rich_text>
			<rich_text foreground="#9090eeee9090">

try with larger privacy budget, see if not so many trees are discarded
</rich_text>
			<rich_text>
</rich_text>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="ensembles" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1622123435.95" ts_lastsave="1622213662.62" unique_id="9">
			<rich_text>Train()
   •  info-logs the number of ensembles
   • called by estimator. (DPGBT).fit()
   • Then all trees get trained
      ◇ and they are assigned to their ensemble by   index modulo #ensembles
   • Theos code does 50 trees 1 ensemble for the 5000 samples case (at least for abalone)
      ◇ for the 300 sample case he uses 5 trees and ignores the nb_trees_per_ensemble

fit()
   •  called by directly after chearing model = (, , , , , ,) model.fit(X,y)
   • example.py only creates 1 (50 tree) ensemble
   • cross_val he would do 50 trees per ensemble



</rich_text>
			<rich_text scale="h2">Train()</rich_text>
			<rich_text>
• so theo does like an ensemble of 50 trees for like 3000 samples.
• so each gets 60 instances.
• Theo randomly selects 60 and checks if the tree improves the ensembles least squares error score.
   ◇ If not, he “skips” that tree (by not even saving it) 
      ▪ its training instances though are keptl usable for the next ones.
   ◇ So the number of trees (out of those 50) is variable and depends on the run! (like 20-30) out of 50

</rich_text>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="scratch" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1622451203.85" ts_lastsave="1624106697.88" unique_id="11">
			<rich_text>

Looking at the example.py results.

   •  so, somehow BFS is either bad or wrong implemented
        probably why it Theo does not mention it in thesis
   • Idk why Theos abalone 5000 graph in thesis has a 0.1pb RMSE of 20-25.
</rich_text>
			<rich_text foreground="#ffffa5a50000">   •  it's because of MinMaxScaler!!!</rich_text>
			<rich_text>


BFS balance_partition=False   is broken!! threading hangs in queue.get() empty something

balance_partition= True makes less trees rejected in 2ndsplit

use_dp seems obsolete for cpp translation. Want only dp.


would be nice to have cross_val in C++,
    it would not need to be side-channel proof
    it's just validation


don't need non-dp option. can just “disable the exp-machanism”
    for now.
    need to check why theo had so many if(no_dp)'s
    
</rich_text>
			<rich_text foreground="#ffffc0c0cbcb">todo checkout easygdb &amp; other github gain computation.</rich_text>
			<rich_text>    
    
</rich_text>
			<rich_text foreground="#ffffc0c0cbcb">todo print all gains and analyze pattern (seems like they stay weirdly constant across feature values)

todo print trees (cpp and python) for easy validation</rich_text>
			<rich_text>

so, theos code says a non-categorical attribute that has only two values, has iidentical gains</rich_text>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="questions 2.0" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1622471704.32" ts_lastsave="1623834483.73" unique_id="12">
			<rich_text>

</rich_text>
			<rich_text foreground="#ffffc0c0cbcb">TODO: debug the result of the pick-formula (algo 2, line 8, base paper)
    does it stay constant across trees?
    is there an easier formula that calculates the same if we have only 1 ensemble ?</rich_text>
			<rich_text>
    
</rich_text>
			<rich_text foreground="#9090eeee9090">do we even need a test set for the “real” hardened application?</rich_text>
			<rich_text>
    
    
</rich_text>
			<rich_text foreground="#ffffc0c0cbcb">TODO read check out theos meeting slides

TODO check if there's a larger testset than abalone 
    (for potential theos hypothesis runs)

TODO   </rich_text>
			<rich_text>is use_decay  used?

TODO implement the non DP for deterministic verification and python comparison of algorithm


</rich_text>
			<rich_text foreground="#9090eeee9090">Only y is scaled right? because we only will add noise to predictions. Right?
Or do we need to scale X before training? Or does it not make a difference?</rich_text>
			<rich_text>
    </rich_text>
			<rich_text foreground="#ffffa5a50000">Esfandiar says only the labels (y)</rich_text>
			<rich_text>

Do we need to look at RMSE % compared to output range?

Theo did not scale the matrix X, resp pythons cross_val_score does not. At least in abalone case.
    somehow the minmaxscaler given to cross_val does only scale y
    Are we not supposed to scale X?
    
    
    
</rich_text>
			<rich_text foreground="#ffffffff0000">I don't understand why scaling y in example.py gets such a low RMSE compared to cross_val_score</rich_text>
			<rich_text>
        it has the same contents as y in cross_val (and cpp)
        idk.
        ignore for now.
</rich_text>
		</node>
		<node custom_icon_id="0" foreground="" is_bold="False" name="questions 3.0" prog_lang="custom-colors" readonly="False" tags="" ts_creation="1624106103.59" ts_lastsave="1624106407.52" unique_id="16">
			<rich_text foreground="#9090eeee9090">After changing the algorithm, the parameters (grid search) are probably off. How to find them again effitiently?</rich_text>
			<rich_text>
        implement whole gridsearch stuff?</rich_text>
		</node>
	</node>
</cherrytree>
