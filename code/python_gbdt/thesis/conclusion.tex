\chapter{Conclusion}

In this work, we merge existing techniques for inducing differentially private decision trees and additionally propose a new induction method, \textit{2-nodes}, which enhances accuracy over both real and synthetic datasets. We show that under strong privacy constraints, our model achieves great accuracy on our synthetic datasets. While this work shows encouraging results in assessing cyber risk, there are still several paths to be explored in future work. First, while the model currently supports both regression and classification tasks, finding optimal privacy bounds (tighter sensitivity bounds lead to enhanced accuracy) for multi-class classification remains an open challenge. Second, and as seen during our model's evaluation, the current literature does not cover privacy leakage attacks targeted at regression models, much less ensemble models such as our gradient boosted decision trees. Developing such attacks would be crucial to properly evaluate our work, and thus constitute a challenging and interesting future research direction. Finally, the space of ensemble methods and their respective induction algorithms is yet another area of potential improvement, that could contribute towards better privacy preserving machine learning methods.